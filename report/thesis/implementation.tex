\chapter{Dynamic Instrumentation Using Code Analysis And Transformation For Detailed GPU Communication Analysis}
This chapter describes in detail how the instrumentation works and will do so in the same order of steps as how an application is processed to generate traces.
First, the original application is instrumented on AST and LLVM IR level for tracing, then the data is generated on the GPU during the execution and transported to the host where it is stored in the trace file.


Disclaimer: No Libraries calls in code possible!

Figure \ref{compilestack} shows the necessary steps to add tracing to an application. The first step performs source-to-source compilation that augments the following kinds of statements in the original source with instructions required
for tracing.
\begin{itemize}
	\item Kernel Declarations
	\item Kernel Definitions
	\item Kernel calls
	\item \verb|__device__| function declaration
	\item \verb|__device__| function definitions
	\item \verb|__device__| Function calls inside a Kernel
\end{itemize}
These augmentations have to be performed for each file that contains either of the above statements individually because the process generated new files
rather than overwriting the original source files. More details on the matter in section \ref{sec:impl:clang}

The next step is the introduction to 

Then explain how the tracing is introduced into the application
\begin{enumerate}
	\item Generate object files from augmented source files and insert tracing with LLVM Plugin:
	\item Linking
\end{enumerate}


\section{Source to Source Compilation in CLang}\label{sec:impl:clang}
\begin{itemize}
	\item User has to know which files need augmentation
	\item Augmentation of one file at a time, since out-of-place code transformation is performed
	\item Working in Clang AST
	\item Find all places in the code that need Augmentation:
	\begin{enumerate}
		\item Kernel Definition: Add set of arguments used for tracing
		\item Kernel Calls: Add arguments used for tracing
		\item Include File offering the tracing utils
	\end{enumerate}
\end{itemize}
\section{Code Transformation in LLVM}
\begin{enumerate}
	\item Pointer Analysis: Proof Global Memory "origin" of Pointer used in Memory operations (Load, Store, Atomics): Context Sensitive, Spase Flow Analysis in SSA, 3 Element Lattice Problemspace, Monotonic Transfer function, Pathological Cases (PhiNodes/Certain Functions)
	\item Versioning: Replicate Device Functions with ambiguous memory spaces
	\item Code Transformation: Insert Instructions used for tracing
	\item Technical Limitations (module boundaries) 
\end{enumerate}

\section{Tracing Process}
	Many applications have non-deterministic executions, eg no fixed number of kernel calls because of varying input data. Examples for is the Breadth-First-Search, which is heavily depending on the underlying graph's structure or PDE solvers which iterate until the
	convergence condition is reached by the residual. Because of this, a static buffer that is simply filled up does no suffice for reliable tracing.
	
	Therefore a producer-consumer between GPU and host is used that ensures the application never runs out of trace-buffer space.
	The buffer containing the generated data is host-mapped memory, which is separated into several bins. The bins are used to reduced
	pressure on the memory system that is generated by the atomic accesses of the producer-consumer setup.
	
	\subsection{Warp-Scope Producer}
	This section focusses on the producer that is running on the device, making sure that data is only written if there space left
	in a buffer. The producer-consumer setup uses a head and a tail index to handle reservation of buffer space and write acknowledgements. Listing \ref{prod-cons} shows the pseudo-algorithm that is performed by the producer.
	\begin{lstlisting}[style=perl]
while((ackIndex > maxIndex) or (res = atomicAdd(resIndex, increment) > maxIndex)) 
buffer[res] = traceData
atomicAdd(ackIndex, increment)
	\end{lstlisting}\label{prod-cons}
	The first line makes sure, that the buffer still has enough space, otherwise the loop waits until the buffer is evacuated by the host. This simplified version 
	
	
	This happens on a warp scope to prevent deadlocks during indices fetching caused by branch divergence inside of warps.
	The deadlock happens because of how GPU handle warp scheduling and and branch divergence. If a branch happens inside a warp, all member threads of this warp execute both branches, but the group of members that should be inactive is masked out.
	
	\subsection{Host Consumer}
	\subsection{Stream Handling}
\begin{itemize}
	\item General Tracing Setup
	\item Producing Data on the Device: Handling Indices on a Warp Scope
	\item Consuming data on the host side
	\item Handling Streams
\end{itemize}


