\chapter{Motivation}
General Purpose GPU computing is a well established part of high performance computing, as many Top500 
systems \cite{} use GPUs to accelarate computation. Because of the fundamentally different design philosophies of CPUs
and GPUs in both hardware and software, optimizations for either systems are usually not compatible. To optimize, an
understanding of an application's characteristics is fundamental

Applications often use multiple kernels or use the same kernel iteratively. This creates patterns of communication because one kernel depends on the information generated by a predecessor. To the knowledge of the author, there is no
work concerned with this class of intra-application communication.

Especially in GPUs, parallel hardware continues scaling with every generation, from ... in Fermi to ... in the current Pascal generation. This scaling is supported by CUDAs programming model, allowing performance portable applications. With increasing hardware capability, communication volume and complexity can also increase.

The analysis of an application can happen on many levels. ... et al. \cite{} categorized these levels and presented several 
metrics for evaluation, including speed and accuracy. GPGPU applications are often analysed with cycle-accurate GPU Simulators. While they provide very accurate results, they have two drawback. 
The first issue is the execution speed, as it takes very long to simulate every hardware cycle in software. 
The second issue is that simulators do not provide models for the latest hardware generations.

Analytical modelling uses mathematical models, trying to create an approximation on the applications behaviour.
While this can be done quickly, accuracy is usually lacking, especially for dynamic or data-depended applications.

Another way of analysis is tracing of existing applications. An application instrumented for tracing logs information
on a desired behaviour and stores the information for later analysis. Instrumented code is faster than simulations as it runs on the actual hardware and can be used on any hardware generation. Although slower than analytical modelling, it is  more accurate since it is generated during the actual application executes, using a real dataset.


%\begin{itemize}
%	\item GPUs are not CPUs. Different design philosophy leads to different application optimizations
%	\item GPU's concurrent hardware continues to scale
%	\item therefore optimizations of data movements, consistency etc. are required to harness compute power of new hardware generations
%	\item Complex Applications have non-trivial communication patterns in data parallel kernels, which are not researched yet.
%	\item This work is aimed to generate understanding of communication patterns to help build and optimize Tools (Mekong etc.) and Applications
%	\item Generate Traces with compiler instrumentation because
%	\item ...Process simulators to slow for real applications and only support outdated Architectures (GPUSim only supports up to Fermi)
%	\item ...analytical modelling usually lack the accuracy to capture exact patterns in complex communication since they are based on simplifications
%	
%\end{itemize}
\section{Goals}
The goal of this Thesis is to develop tooling for instrumentation to perform dynamic global memory tracing in GPU applications. The instrumentation will happen at compile time using custom plugins for Clang and LLVM to transform the source code of the
original application. With this setup, traces can be generated with any application that provides source code and
across different generations of NVidia hardware. A loss in performance resulting from the traces will be tolerated.

The generated traces will be used to analyse how CTAs and kernels communicate during the execution of an application. 
The communication will be analysed on a qualitative level by classifying how the data is exchanged and on a quantitative level with metrics like volume, frequency and density to describe kernel and CTA interactions.


\section{Outline}
	\paragraph{Chapter 2} presents technological background information. It will introduce BSP, GPUs, LLVM, SSA and the compiler techniques used to transform the code of the original application.
	\paragraph{Chapter 3} discusses work related to this Thesis. It will explore work in the field of code instrumentation and GPU performance analysis.
	\paragraph{Chapter 4} defines what communication in the context of this work and explores the analysis space.
	\paragraph{Chapter 5} presents how the tracing is realized including the compile stack, AST manipulation and deeper code analysis in LLVM's intermidiate representation (IR).
	\paragraph{Chapter 6} presents the set of applications that will be analysed, the different metrics are explained in detail and the results of the analysis are discussed in length.
	\paragraph{Chapter 7} concludes and summarizes the results of this Thesis and discusses possible future directions this project could take.
