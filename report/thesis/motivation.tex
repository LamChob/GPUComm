\chapter{Motivation}
General Purpose GPU computing is a well established part of high performance computing, as many Top500 
systems \cite{Top500} use GPUs to accelarate computation. Because of the fundamentally different design philosophies of CPUs
and GPUs in both hardware and software, optimizations for either system are usually not compatible. To optimize, an
understanding of an application's characteristics is fundamental.

Applications often use multiple kernels or use the same kernel iteratively. This creates patterns of communication because one kernel depends on the information generated by a predecessor. To the knowledge of the author, there is no
work concerned with this class of intra-application communication in GPUs.

Especially in GPUs, parallel hardware continues scaling with every generation, from 512 CUDA cores in Fermi  \cite{FermiPaper} to 3840 CUDA cores in the current Pascal generation \cite{PascalPaper}. This scaling is supported by CUDAs programming model, allowing performance portable applications. With increasing potential parallelism and concurrency, communication patterns, volumes and complexity also increase or change.

The analysis of an application can happen on many levels. Spafford et al. \cite{Spafford:2012:ADS:2388996.2389110} categorized these levels and presented several 
metrics for evaluation, including speed and accuracy. GPGPU applications can be analysed with cycle-accurate GPU Simulators. While they provide very accurate results, they have two drawback. 
The first issue is the execution speed, as it takes very long to simulate every hardware cycle in software. 
The second issue is that simulators do not provide models for the latest hardware generations. GPGPU-Sim, for example, only supports Fermi architectures. \cite{gpgpu}

Analytical modelling uses mathematical models, trying to create an approximation on the applications behaviour.
While this can be done quickly, accuracy is usually lacking, especially for dynamic or data-depended applications.

Another way of analysis is tracing of existing applications. An application instrumented for tracing logs information on a desired metric and stores the information for later analysis. Instrumented code is faster than simulations as it runs on the actual hardware and can be used on any hardware generation. Although slower than analytical modelling, it is  more accurate since it is generated while the actual application executes, using a real dataset.


%\begin{itemize}
%	\item GPUs are not CPUs. Different design philosophy leads to different application optimizations
%	\item GPU's concurrent hardware continues to scale
%	\item therefore optimizations of data movements, consistency etc. are required to harness compute power of new hardware generations
%	\item Complex Applications have non-trivial communication patterns in data parallel kernels, which are not researched yet.
%	\item This work is aimed to generate understanding of communication patterns to help build and optimize Tools (Mekong etc.) and Applications
%	\item Generate Traces with compiler instrumentation because
%	\item ...Process simulators to slow for real applications and only support outdated Architectures (GPUSim only supports up to Fermi)
%	\item ...analytical modelling usually lack the accuracy to capture exact patterns in complex communication since they are based on simplifications
%	
%\end{itemize}
\section{Goals}
This thesis has two main goals. First, develop tooling for instrumentation of GPU applications to perform dynamic global memory tracing. The instrumentation will happen at compile time using custom plugins for Clang and LLVM to transform the source code of the
original application. With this setup, traces can be generated for any application providing source code,
across different generations of Nvidia hardware. A loss in performance resulting from the traces will be tolerated.

The second goal is to use the generated traces to analyse how CTAs and kernels communicate during the execution of an application. The communication will be analysed on a qualitative level by classifying how the data is exchanged and on a quantitative level with metrics like volume, frequency and density to describe kernel and CTA interactions.


\section{Outline}
	\paragraph{Chapter 2} presents technological background information. It will introduce BSP, GPUs, LLVM, SSA and the compiler techniques used to transform the code of the original application.
	\paragraph{Chapter 3} discusses work related to this Thesis. It will explore work in the field of code instrumentation and GPU performance analysis.
	\paragraph{Chapter 4} defines communication in the context of this work and explores the analysis space.
	\paragraph{Chapter 5} presents how applications are instrumented using AST manipulation and deeper code analysis in LLVM's intermidiate representation (IR).
	\paragraph{Chapter 6} presents the set of applications that will be analysed, the different metrics are explained in detail and the results of the analysis are discussed.
	\paragraph{Chapter 7} concludes and summarizes the results of this thesis and discusses possible future directions this project could take.
